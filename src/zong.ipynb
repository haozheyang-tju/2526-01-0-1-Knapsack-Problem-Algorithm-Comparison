{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759b1e31",
   "metadata": {},
   "source": [
    "#算法汇总\n",
    "# 0/1背包问题的贪心算法设计与实现\n",
    "**姓名：毛子鋆**\n",
    "**学号：2025439109**\n",
    "**学院：天津大学福州国际联合学院**\n",
    "**专业：电子信息**\n",
    "\n",
    "**姓名：刘伦**\n",
    "**学号：2025439114**\n",
    "**学院：天津大学福州国际联合学院**\n",
    "**专业：电子信息**\n",
    "\n",
    "**姓名：梁天宇**\n",
    "**学号：2025439111**\n",
    "**学院：天津大学福州国际联合学院**\n",
    "**专业：电子信息**\n",
    "\n",
    "**姓名：张涛**\n",
    "**学号：2025439107**\n",
    "**学院：天津大学福州国际联合学院**\n",
    "**专业：电子信息**\n",
    "\n",
    "**姓名：邓康**\n",
    "**学号：2025439148**\n",
    "**学院：天津大学福州国际联合学院**\n",
    "**专业：电子信息**\n",
    "\n",
    "**姓名：杨昊哲**\n",
    "**学号：2025439122**\n",
    "**学院：天津大学福州国际联合学院**\n",
    "**专业：电子信息**\n",
    "\n",
    "\n",
    "\n",
    "**目标**：在 0/1 背包（每个物品要么选要么不选）中，设计仅基于贪心思想的快速近似方法。\n",
    "\n",
    "---\n",
    "\n",
    "## 算法 A：GreedyDensity（标准贪心）\n",
    "\n",
    "- **思路**：按价值密度\n",
    "  $$\n",
    "  \\rho_i = \\frac{v_i}{w_i}\n",
    "  $$\n",
    "  从大到小排序，依次遍历物品，遇到还能装入背包的就装入（\"能装就装\"的前缀策略）。\n",
    "\n",
    "- **优点**：实现简单，时间复杂度主要由排序开销决定，为\n",
    "  $$\n",
    "  O(n \\log n)\n",
    "  $$\n",
    "\n",
    "- **缺点**：当存在\"价值极高但密度略低、且重量接近容量\"的重物品时，贪心可能被一批密度略高但价值较低的小物品\"诱导\"，从而错失最关键的物品，解质量可能与最优解有较大差距。\n",
    "\n",
    "---\n",
    "\n",
    "## 算法 B：Greedy+Max（BYOG+Max 的线性特化）\n",
    "\n",
    "- **思路**：在 GreedyDensity 得到的一组解 $S_g$ 与\"所有单个、且能放入背包的物品中价值最高的一件\" $j^*$ 之间取价值更高者作为最终解，即返回\n",
    "  $$\n",
    "  \\arg\\max\\{\\,v(S_g),\\ v(j^*)\\,\\}\n",
    "  $$\n",
    "  这种做法也常被称为 **Greedy + Singleton** 或 **Greedy Redux**。\n",
    "\n",
    "- **作用**：用\"最佳单件兜底\"补上标准贪心的短板。在许多典型的\"贪心陷阱\"构造中（例如存在密度略低但价值更高、重量接近容量的关键单件），Greedy+Max 能显著提升解质量。\n",
    "\n",
    "- **理论性质（这里只做提示，证明放在'理论分析'章节）**：Greedy+Max 在 0/1 背包上具有\n",
    "  $$\n",
    "  \\tfrac{1}{2}\n",
    "  $$\n",
    "  的近似保证，即输出解的价值至少是最优解 $\\mathrm{OPT}$ 的一半。\n",
    "\n",
    "## 算法 C：algo_beam_search(集束搜索)\n",
    "\n",
    "- **思路**：Classic Beam Search 通过引入参数 B（束宽，Beam Width），在每一轮扩展中保留前B个最有潜力的部分解，试图以 O(B)的线性额外开销换取对解空间的更充分探索。基准定位：在本章实验中，它作为衡量“简单启发式改进”有效性的标尺。\n",
    "---\n",
    "\n",
    "## 算法 D：algo_beam_search_optimized(有界集束搜索)\n",
    "\n",
    "- **思路**：针对经典集束搜索易被“高初始增益但低长远价值”的诱饵元素误导的问题，该算法引入了基于子模性上界（Upper Bound）的剪枝与筛选机制。它不仅仅依据当前的目标函数值 f(S)进行排序，而是结合了对剩余容量潜在增益的估计（bounding），从而在波束筛选阶段保留那些当前值稍低但具备更高增长潜力的路径。这种\"引导式\"搜索在近年的子模最大化研究中被证明能显著提升鲁棒性。\n",
    "\n",
    "#### 算法 E：GeneticAlgorithm（标准遗传算法）\n",
    "遗传算法是一种模拟自然选择和生物进化的元启发式优化算法，由 John Holland 于 1975 年提出。其核心思想包括：\n",
    "\n",
    "- **编码（Encoding）**：将解表示为染色体（如二进制串）。在背包问题中，长度为 $n$ 的二进制串表示是否选择第 $i$ 个物品。\n",
    "  \n",
    "- **初始化种群（Initialization）**：随机生成若干个体（候选解）构成初始种群。\n",
    "  \n",
    "- **适应度函数（Fitness Function）**：评估个体优劣。对背包问题，若超重则适应度为 0（无效解），否则为总价值。\n",
    "\n",
    "- **选择（Selection）**：按适应度高低选择优秀个体参与繁殖（如轮盘赌、锦标赛、排序选择）。本代码采用排序后取前50% 。\n",
    "  \n",
    "- **交叉（Crossover）**：\t模拟基因重组，生成新个体。支持单点、两点、均匀交叉。\n",
    "  \n",
    "- **变异（Mutation）**：\t引入随机扰动，防止早熟收敛。支持位翻转、交换变异。\n",
    "\n",
    "- **迭代（Evolution）**：\t重复选择→交叉→变异，直至满足终止条件（如代数上限）。\n",
    "\n",
    "---\n",
    "\n",
    "#### 算法 F：ModifiedGeneticAlgorithm（修改后的遗传算法）\n",
    "\n",
    "- **思路**：ModifiedGeneticAlgorithm是在标准遗传算法基础上引入多层次并行搜索与重启机制的一种增强型方法，其核心目标是提升在求解0-1背包问题时的全局搜索能力、收敛速度以及对复杂约束条件的适应性。相较于前文所述的标准遗传算法，该方法在种群初始化、演化结构、探索策略和计算资源利用等方面进行了系统性优化。\n",
    "\n",
    "### 算法G：标准模拟退火 (SA_Fast)\n",
    "- 基于Metropolis准则的经典模拟退火算法\n",
    "- 采用指数降温策略\n",
    "- 包含快速邻域搜索和修复机制\n",
    "- 针对运行时间进行了参数优化\n",
    "\n",
    "### 算法H：记忆模拟退火 (MemeticSA_Fast)\n",
    "- 结合了模拟退火、局部搜索和种群进化策略\n",
    "- 使用小规模种群并行搜索\n",
    "- 在每次降温迭代中执行局部优化\n",
    "- 包含交叉、变异和锦标赛选择操作\n",
    "\n",
    "### 算法 I：Branch-and-Bound Basic（基础分支限界）\n",
    "\n",
    "- **思路**：采用深度优先搜索（DFS）策略，在递归树中枚举每个物品的选（1）与不选（0）分支。在每一个树节点，算法计算一个分数背包上界：假设后续物品可以按价值密度$（\\rho_i = \\frac{v_i}{w_i}）$\n",
    "降序部分装入，由此得到的最大可能价值\n",
    "\n",
    "- **优点**：能保证找到全局最优解。分数背包上界计算高效，提供了有效的剪枝依据\n",
    "\n",
    "- **缺点**：搜索策略（DFS）相对盲目，可能长时间探索潜力较低的子树。剪枝仅依赖一个较宽松的上界，在复杂实例中搜索树规模仍可能爆炸性增长，求解效率不稳定。\n",
    "\n",
    "---\n",
    "\n",
    "### 算法 J：Enhanced Branch-and-Bound via Probing & Node Selection（探测和最佳界限节点选择优化）\n",
    "\n",
    "- **思路**：在正式对一个变量（物品）进行分支（设为0或1）之前，进行预探索,临时固定该变量，快速评估其两个子问题的线性松弛上界。在节点选择上选择优先级最高（即上界最紧、理论上潜力最大）的节点。\n",
    "  $$\n",
    "  P(node)=UB_{frac}(node)\n",
    "  $$\n",
    "\n",
    "- **作用**：改变了基础版本中深度优先的“盲目”搜索顺序。该策略能引导算法最快地找到高质量可行解，从而迅速提升全局下界，配合探测技术实现更早、更有效的剪\n",
    "\n",
    "- **理论性质（这里只做提示，证明放在'理论分析'章节）**：“探测”与“基于上界的节点选择”相结合，能系统性减少为证明最优性所需探索的搜索树规模（节点数）。这直接转化为更短的求解时间，尤其是在那些传统方法需要大量回溯的“难”实例上。\n",
    "\n",
    "### 算法 K：ImprovedBPSO（改进二进制粒子群优化）\n",
    "\n",
    "- **思路**：在基础二进制粒子群优化（BPSO）框架上，引入多维度改进平衡全局探索与局部开发：通过自适应惯性权重\n",
    "  $$\n",
    "  w = w_{\\text{max}} - \\frac{w_{\\text{max}} - w_{\\text{min}}}{T_{\\text{max}}} \\cdot t\n",
    "  $$\n",
    "  （$t$ 为当前迭代次数，$T_{\\text{max}}$ 为最大迭代次数）调整粒子搜索策略，结合精英保留、位变异操作\n",
    "  $$\n",
    "  x_{i,d} = 1 - x_{i,d} \\quad (\\text{以概率 } P_m)\n",
    "  $$\n",
    "  与邻域局部搜索，最终通过 Sigmoid 转移函数\n",
    "  $$\n",
    "  s_{i,d} = \\frac{1}{1 + e^{-v_{i,d}^{t+1}}}\n",
    "  $$\n",
    "  将连续速度映射为 0/1 二进制位置，快速生成高质量近似解。\n",
    "\n",
    "- **优点**：时间复杂度由迭代次数、粒子数和物品数决定，为\n",
    "  $$\n",
    "  O(T \\cdot N \\cdot n)\n",
    "  $$\n",
    "  可高效适配大规模 0/1 背包问题（$n>100$）；多维度改进有效缓解早熟收敛，解质量远优于基础贪心算法，实践中接近全局最优解。\n",
    "\n",
    "- **缺点**：无严格的常数近似保证，极端案例下解质量仅达最优解 $\\mathrm{OPT}$ 的 50% 左右；参数（惯性权重、变异概率、粒子数等）高度敏感，需针对具体问题调优才能达到理想效果。\n",
    "\n",
    "---\n",
    "\n",
    "### 算法 L：二进制布谷鸟搜索(BCS)算法\n",
    "\n",
    "- **思路**：基于布谷鸟寄生繁殖的自然行为，适配 0/1 背包问题的二进制决策空间进行改进：首先初始化一组鸟巢（对应二进制解向量，$x_i \\in \\{0,1\\}$ 表示是否选择第 $i$ 个物品），通过莱维飞行（Levy Flight）生成新解，莱维飞行步长满足重尾分布\n",
    "  $$\n",
    "  \\text{Step} \\sim \\text{Levy}(\\beta) = \\frac{\\Gamma(1+\\beta) \\sin(\\pi\\beta/2)}{\\Gamma((1+\\beta)/2) \\beta 2^{(\\beta-1)/2}} \\cdot \\frac{u}{|v|^{1/\\beta}}\n",
    "  $$\n",
    "  （$\\beta \\in (1,2]$，$u,v$ 服从标准正态分布 $N(0,1)$）；再通过 Sigmoid 映射函数\n",
    "  $$\n",
    "  p_{i,d} = \\frac{1}{1 + e^{-\\text{Step}_{i,d}}}\n",
    "  $$\n",
    "  将连续步长转换为二进制选择概率，通过随机抽样生成新鸟巢；最后以发现概率 $p_a$ 舍弃劣质鸟巢并随机生成新鸟巢，迭代直至满足收敛条件或达到最大迭代次数，输出最优鸟巢对应的解。\n",
    "\n",
    "- **优点**：全局探索能力优异，莱维飞行的长步长特性可有效跳出局部最优，在多峰值 0/1 背包问题中表现突出；参数数量少（仅需设置鸟巢数量、发现概率 $p_a$、$\\beta$ 系数），实现简单且易于工程落地；时间复杂度为\n",
    "  $$\n",
    "  O(T \\cdot M \\cdot n)\n",
    "  $$\n",
    "  （$M$ 为鸟巢数量，$T$ 为最大迭代次数），中等规模问题（$n<200$）下运行效率稳定且波动小。\n",
    "\n",
    "- **缺点**：局部开发能力较弱，迭代后期收敛速度缓慢，难以进一步精细化提升解质量；无严格近似保证，极端场景下解质量波动较大；对莱维飞行参数 $\\beta$ 敏感，大规模问题（$n>200$）下鸟巢数量激增，时间与空间开销显著上升，无法高效适配。\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1fc55d",
   "metadata": {},
   "source": [
    "# 各个算法具体实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a0d96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "算法初步运行完成\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import zlib\n",
    "import tracemalloc\n",
    "from dataclasses import dataclass,field\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import heapq\n",
    "\n",
    "# ============================================================\n",
    "#  一、稳定哈希 & 全局设置  ——  保证随机可复现（数据集定义）\n",
    "# ============================================================\n",
    "\n",
    "def stable_hash_str(*parts) -> int:\n",
    "    \"\"\"跨平台/跨进程稳定的 32 位哈希，用于生成可复现的随机种子。\"\"\"\n",
    "    s = \"|\".join(str(p) for p in parts)\n",
    "    return zlib.adler32(s.encode(\"utf-8\")) & 0xffffffff\n",
    "\n",
    "# 固定顶层随机种子（库级）\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "OUTDIR = \"outputs_exp_section3\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "#  二、数据结构定义  ——  Item & 算法接口\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class Item:\n",
    "    w: int   # weight\n",
    "    v: int   # value\n",
    "    idx: int # 原始索引（用于回溯/调试）\n",
    "\n",
    "# 所有算法统一接口： (items, C) -> (value, chosen_indices)\n",
    "AlgoFn = Callable[[List[Item], int], Tuple[int, List[int]]]\n",
    "\n",
    "# ============================================================\n",
    "#  三、基线算法 —— Greedy / BeamSearch\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  1.毛子鋆\n",
    "# ============================================================\n",
    "\n",
    "def greedy_density(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"标准贪心：按 v/w 从大到小排序，能放就放。\"\"\"\n",
    "    items_sorted = sorted(items, key=lambda x: (x.v / x.w, x.v), reverse=True)\n",
    "    tw = 0\n",
    "    tv = 0\n",
    "    chosen: List[int] = []\n",
    "    for it in items_sorted:\n",
    "        if tw + it.w <= C:\n",
    "            tw += it.w\n",
    "            tv += it.v\n",
    "            chosen.append(it.idx)\n",
    "    return tv, chosen\n",
    "\n",
    "def greedy_plus_max(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"Greedy+Max：比较 Greedy 解和 价值最高的单件物品。\"\"\"\n",
    "    g_val, g_set = greedy_density(items, C)\n",
    "    best_single = None\n",
    "    for it in items:\n",
    "        if it.w <= C and (best_single is None or it.v > best_single.v):\n",
    "            best_single = it\n",
    "\n",
    "    if best_single is None:\n",
    "        return g_val, g_set\n",
    "    if best_single.v > g_val:\n",
    "        return best_single.v, [best_single.idx]\n",
    "    return g_val, g_set\n",
    "\n",
    "# ============================================================\n",
    "#  2.刘伦\n",
    "# ============================================================\n",
    "\n",
    "def algo_beam_search(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"基础 Beam Search (BS)。\"\"\"\n",
    "    BEAM_WIDTH = 50 \n",
    "    current_states = [(0, 0, [])] \n",
    "    sorted_items = sorted(items, key=lambda x: x.v/x.w, reverse=True)\n",
    "\n",
    "    for item in sorted_items:\n",
    "        next_states = []\n",
    "        for c_val, c_w, c_path in current_states:\n",
    "            next_states.append((c_val, c_w, c_path))\n",
    "            if c_w + item.w <= C:\n",
    "                new_path = c_path + [item.idx]\n",
    "                next_states.append((c_val + item.v, c_w + item.w, new_path))\n",
    "        \n",
    "        next_states.sort(key=lambda x: x[0], reverse=True)\n",
    "        current_states = next_states[:BEAM_WIDTH]\n",
    "\n",
    "    best_val, _, best_path = current_states[0]\n",
    "    return best_val, best_path\n",
    "\n",
    "\n",
    "def algo_beam_search_optimized(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"改进版 Beam Search：引入线性松弛上界和优势剪枝。\"\"\"\n",
    "    BEAM_WIDTH = 50\n",
    "    sorted_items = sorted(items, key=lambda x: x.v/x.w, reverse=True)\n",
    "    n = len(sorted_items)\n",
    "\n",
    "    def get_upper_bound(curr_val, curr_w, start_idx):\n",
    "        remaining_cap = C - curr_w\n",
    "        if remaining_cap < 0: return 0\n",
    "        bound = curr_val\n",
    "        idx = start_idx\n",
    "        while idx < n and sorted_items[idx].w <= remaining_cap:\n",
    "            bound += sorted_items[idx].v\n",
    "            remaining_cap -= sorted_items[idx].w\n",
    "            idx += 1\n",
    "        if idx < n and remaining_cap > 0:\n",
    "            bound += remaining_cap * (sorted_items[idx].v / sorted_items[idx].w)\n",
    "        return bound\n",
    "\n",
    "    init_bound = get_upper_bound(0, 0, 0)\n",
    "    current_states = [{'priority': init_bound, 'val': 0, 'w': 0, 'path': []}]\n",
    "\n",
    "    for i in range(n):\n",
    "        item = sorted_items[i]\n",
    "        next_states = []\n",
    "        \n",
    "        for state in current_states:\n",
    "            c_val, c_w, c_path = state['val'], state['w'], state['path']\n",
    "            # Branch 1: Drop\n",
    "            ub_drop = get_upper_bound(c_val, c_w, i + 1)\n",
    "            next_states.append({'priority': ub_drop, 'val': c_val, 'w': c_w, 'path': c_path})\n",
    "            # Branch 2: Take\n",
    "            if c_w + item.w <= C:\n",
    "                new_val = c_val + item.v\n",
    "                new_w = c_w + item.w\n",
    "                ub_take = get_upper_bound(new_val, new_w, i + 1)\n",
    "                next_states.append({'priority': ub_take, 'val': new_val, 'w': new_w, 'path': c_path + [item.idx]})\n",
    "\n",
    "        # Pruning & Sorting\n",
    "        next_states.sort(key=lambda x: (-x['val'], x['w']))\n",
    "        pruned_states = []\n",
    "        min_w_so_far = float('inf')\n",
    "        for state in next_states:\n",
    "            if state['w'] < min_w_so_far:\n",
    "                pruned_states.append(state)\n",
    "                min_w_so_far = state['w']\n",
    "        \n",
    "        pruned_states.sort(key=lambda x: x['priority'], reverse=True)\n",
    "        current_states = pruned_states[:BEAM_WIDTH]\n",
    "\n",
    "    if not current_states: return 0, []\n",
    "    best_state = max(current_states, key=lambda x: x['val'])\n",
    "    return best_state['val'], best_state['path']\n",
    "\n",
    "# ============================================================\n",
    "#  3.梁天宇\n",
    "# ============================================================\n",
    "\n",
    "def _ga_init_population(n_items: int, pop_size: int, w_arr: np.ndarray, C: int) -> np.ndarray:\n",
    "    \"\"\"生成初始种群，尽量保证可行性\"\"\"\n",
    "    # 随机生成布尔矩阵 (PopSize, N)\n",
    "    pop = np.random.randint(0, 2, size=(pop_size, n_items)).astype(bool)\n",
    "    # 修正超重个体：随机移除物品直到满足容量\n",
    "    total_w = pop.dot(w_arr)\n",
    "    overloaded_indices = np.where(total_w > C)[0]\n",
    "    \n",
    "    for idx in overloaded_indices:\n",
    "        while total_w[idx] > C:\n",
    "            # 随机找一个为1的位置置0\n",
    "            candidates = np.where(pop[idx])[0]\n",
    "            if len(candidates) == 0: break\n",
    "            remove_idx = np.random.choice(candidates)\n",
    "            pop[idx, remove_idx] = 0\n",
    "            total_w[idx] -= w_arr[remove_idx]\n",
    "    return pop\n",
    "\n",
    "def _ga_fitness(pop: np.ndarray, w_arr: np.ndarray, v_arr: np.ndarray, C: int) -> np.ndarray:\n",
    "    \"\"\"批量计算适应度，超重者适应度归零\"\"\"\n",
    "    total_w = pop.dot(w_arr)\n",
    "    total_v = pop.dot(v_arr)\n",
    "    # 将超重个体的价值设为 0\n",
    "    total_v[total_w > C] = 0\n",
    "    return total_v\n",
    "\n",
    "def _ga_crossover(pop: np.ndarray, selection_rate: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"统一交叉操作 (Uniform Crossover + Selection)\"\"\"\n",
    "    pop_size, n_genes = pop.shape\n",
    "    # 1. Selection: 保留前 selection_rate 的精英\n",
    "    n_parents = int(pop_size * selection_rate)\n",
    "    # 假设 pop 已经按适应度排序过，直接取前 n_parents\n",
    "    parents = pop[:n_parents]\n",
    "    \n",
    "    # 2. Crossover: 生成剩余个体\n",
    "    n_children = pop_size - n_parents\n",
    "    if n_children <= 0: return parents\n",
    "\n",
    "    # 随机选择父母索引\n",
    "    p1_indices = np.random.randint(0, n_parents, size=n_children)\n",
    "    p2_indices = np.random.randint(0, n_parents, size=n_children)\n",
    "    \n",
    "    # Uniform Crossover 掩码\n",
    "    mask = np.random.randint(0, 2, size=(n_children, n_genes)).astype(bool)\n",
    "    children = np.where(mask, parents[p1_indices], parents[p2_indices])\n",
    "    \n",
    "    return np.vstack((parents, children))\n",
    "\n",
    "def _ga_mutation(pop: np.ndarray, mutation_rate: float = 0.01) -> np.ndarray:\n",
    "    \"\"\"位翻转变异\"\"\"\n",
    "    # 生成变异掩码，只有 True 的地方翻转\n",
    "    mask = np.random.random(pop.shape) < mutation_rate\n",
    "    return np.logical_xor(pop, mask)\n",
    "\n",
    "def run_GA(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    [重命名] 标准遗传算法 (原 main.py 中的 run_GA)\n",
    "    简化后的单种群逻辑，使用 Numpy 加速。\n",
    "    \"\"\"\n",
    "    # 1. 数据准备\n",
    "    w_arr = np.array([it.w for it in items], dtype=np.int32)\n",
    "    v_arr = np.array([it.v for it in items], dtype=np.int32)\n",
    "    idx_arr = np.array([it.idx for it in items])\n",
    "    n = len(items)\n",
    "    \n",
    "    # 参数设置\n",
    "    POP_SIZE = min(50, n * 2)  # 适度限制规模\n",
    "    GENERATIONS = 15\n",
    "    \n",
    "    # 2. 初始化\n",
    "    pop = _ga_init_population(n, POP_SIZE, w_arr, C)\n",
    "    \n",
    "    best_v = 0\n",
    "    best_gene = np.zeros(n, dtype=bool)\n",
    "\n",
    "    # 3. 进化循环\n",
    "    for _ in range(GENERATIONS):\n",
    "        # 计算适应度\n",
    "        fitness = _ga_fitness(pop, w_arr, v_arr, C)\n",
    "        \n",
    "        # 记录最优\n",
    "        curr_max_idx = np.argmax(fitness)\n",
    "        if fitness[curr_max_idx] > best_v:\n",
    "            best_v = fitness[curr_max_idx]\n",
    "            best_gene = pop[curr_max_idx].copy()\n",
    "            \n",
    "        # 排序\n",
    "        sorted_indices = np.argsort(fitness)[::-1] # 降序\n",
    "        pop = pop[sorted_indices]\n",
    "        \n",
    "        # 交叉 & 变异\n",
    "        pop = _ga_crossover(pop, selection_rate=0.5)\n",
    "        pop = _ga_mutation(pop, mutation_rate=0.01 / (n/100 + 1)) # 动态变异率\n",
    "\n",
    "    # 4. 解析结果\n",
    "    chosen_mask = best_gene.astype(bool)\n",
    "    chosen_indices = idx_arr[chosen_mask].tolist()\n",
    "    return int(best_v), chosen_indices\n",
    "\n",
    "def run_iGA(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    [重命名] 岛屿模型遗传算法 (原 main.py 中的 run_iGA)\n",
    "    特性：多岛并行 + 随机重启 + 动态迁移\n",
    "    \"\"\"\n",
    "    w_arr = np.array([it.w for it in items], dtype=np.int32)\n",
    "    v_arr = np.array([it.v for it in items], dtype=np.int32)\n",
    "    idx_arr = np.array([it.idx for it in items])\n",
    "    n = len(items)\n",
    "\n",
    "    N_ISLANDS = 4\n",
    "    ISLAND_POP = min(100, n * 2)\n",
    "    CYCLES = 5  # 迁移轮次\n",
    "    GENS_PER_CYCLE = 10\n",
    "\n",
    "    def run_island_thread(seed_offset):\n",
    "        \"\"\"单个岛屿的进化过程\"\"\"\n",
    "        np.random.seed(seed_offset + int(time.time()))\n",
    "        pop = _ga_init_population(n, ISLAND_POP, w_arr, C)\n",
    "        local_best_v = 0\n",
    "        local_best_gene = None\n",
    "\n",
    "        for _ in range(GENS_PER_CYCLE):\n",
    "            fitness = _ga_fitness(pop, w_arr, v_arr, C)\n",
    "            \n",
    "            # 更新局部最优\n",
    "            curr_max_idx = np.argmax(fitness)\n",
    "            if fitness[curr_max_idx] > local_best_v:\n",
    "                local_best_v = fitness[curr_max_idx]\n",
    "                local_best_gene = pop[curr_max_idx].copy()\n",
    "\n",
    "            # 排序 & 进化\n",
    "            sorted_indices = np.argsort(fitness)[::-1]\n",
    "            pop = pop[sorted_indices]\n",
    "            pop = _ga_crossover(pop, selection_rate=0.4) # 压力稍大\n",
    "            pop = _ga_mutation(pop, mutation_rate=0.02)  # 变异稍大\n",
    "            \n",
    "            # 随机重启机制 (来自 ModifiedGA)\n",
    "            # 如果种群同质化严重（最高分和平均分接近），部分重置\n",
    "            if np.mean(fitness[:10]) - np.mean(fitness) < 1e-5:\n",
    "                # 保留前 20%，其余重置\n",
    "                n_keep = int(ISLAND_POP * 0.2)\n",
    "                pop[n_keep:] = _ga_init_population(n, ISLAND_POP - n_keep, w_arr, C)\n",
    "\n",
    "        return pop[:int(ISLAND_POP * 0.2)], local_best_v, local_best_gene # 返回精英\n",
    "\n",
    "    global_best_v = 0\n",
    "    global_best_gene = np.zeros(n, dtype=bool)\n",
    "\n",
    "    # 岛屿循环\n",
    "    with ThreadPoolExecutor(max_workers=N_ISLANDS) as executor:\n",
    "        for cycle in range(CYCLES):\n",
    "            futures = [executor.submit(run_island_thread, i*100 + cycle) for i in range(N_ISLANDS)]\n",
    "            \n",
    "            # 收集结果 (在实际复杂实现中这里会做迁移，这里简化为并发搜索)\n",
    "            for f in as_completed(futures):\n",
    "                elites, best_v, best_gene = f.result()\n",
    "                if best_v > global_best_v:\n",
    "                    global_best_v = best_v\n",
    "                    global_best_gene = best_gene\n",
    "            \n",
    "    chosen_mask = global_best_gene.astype(bool)\n",
    "    chosen_indices = idx_arr[chosen_mask].tolist()\n",
    "    return int(global_best_v), chosen_indices\n",
    "\n",
    "# ============================================================\n",
    "#  4.张涛\n",
    "# ============================================================\n",
    "def simulated_annealing_knapsack_fast(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    快速模拟退火算法 - 优化参数以减少运行时间\n",
    "    \n",
    "    主要优化：\n",
    "    1. 降低迭代次数\n",
    "    2. 提高冷却速率\n",
    "    3. 减少最大停滞次数\n",
    "    \"\"\"\n",
    "    n = len(items)\n",
    "    \n",
    "    # 优化后的参数设置 - 大幅减少运行时间\n",
    "    if n <= 50:\n",
    "        initial_temp = 300      # 降低初始温度\n",
    "        cooling_rate = 0.97     # 提高冷却速率，更快降温\n",
    "        iterations_per_temp = 30  # 大幅减少每个温度的迭代次数\n",
    "        max_stagnation = 10     # 减少最大停滞次数\n",
    "    elif n <= 100:\n",
    "        initial_temp = 200\n",
    "        cooling_rate = 0.96\n",
    "        iterations_per_temp = 20\n",
    "        max_stagnation = 8\n",
    "    else:  # 大规模实例\n",
    "        initial_temp = 150\n",
    "        cooling_rate = 0.95\n",
    "        iterations_per_temp = 15  # 进一步减少\n",
    "        max_stagnation = 5\n",
    "    \n",
    "    # 初始化当前解 - 简化版贪心\n",
    "    def initialize_solution():\n",
    "        density_sorted = sorted(range(n), key=lambda i: items[i].v / items[i].w, reverse=True)\n",
    "        solution = [0] * n\n",
    "        current_weight = 0\n",
    "        \n",
    "        # 只选择前几个物品，减少初始化时间\n",
    "        max_items = min(20, n)  # 限制初始化物品数量\n",
    "        for idx in density_sorted[:max_items]:\n",
    "            if current_weight + items[idx].w <= C:\n",
    "                solution[idx] = 1\n",
    "                current_weight += items[idx].w\n",
    "        return solution\n",
    "    \n",
    "    def evaluate(solution):\n",
    "        total_value = 0\n",
    "        total_weight = 0\n",
    "        for i in range(n):\n",
    "            if solution[i] == 1:\n",
    "                total_value += items[i].v\n",
    "                total_weight += items[i].w\n",
    "        if total_weight > C:\n",
    "            return max(0, total_value - 1000 * (total_weight - C))\n",
    "        return total_value\n",
    "    \n",
    "    # 简化邻域操作\n",
    "    def generate_neighbor_fast(current_solution):\n",
    "        new_solution = current_solution.copy()\n",
    "        \n",
    "        # 只使用最简单的翻转操作，减少计算\n",
    "        if random.random() < 0.7:  # 70%概率使用简单翻转\n",
    "            idx = random.randint(0, n-1)\n",
    "            new_solution[idx] = 1 - new_solution[idx]\n",
    "        else:  # 30%概率使用swap操作\n",
    "            idx1, idx2 = random.sample(range(n), 2)\n",
    "            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n",
    "        \n",
    "        return new_solution\n",
    "    \n",
    "    def repair_solution_fast(solution):\n",
    "        current_weight = sum(items[i].w for i in range(n) if solution[i] == 1)\n",
    "        \n",
    "        # 如果超重，移除最少物品达到可行\n",
    "        if current_weight > C:\n",
    "            selected_indices = [i for i in range(n) if solution[i] == 1]\n",
    "            if selected_indices:\n",
    "                # 按价值密度升序排序，移除低密度物品\n",
    "                sorted_by_density = sorted(\n",
    "                    selected_indices,\n",
    "                    key=lambda i: items[i].v / items[i].w\n",
    "                )\n",
    "                # 只移除必要的最少物品\n",
    "                for idx in sorted_by_density:\n",
    "                    if current_weight <= C:\n",
    "                        break\n",
    "                    solution[idx] = 0\n",
    "                    current_weight -= items[idx].w\n",
    "        return solution\n",
    "    \n",
    "    # 模拟退火主循环 - 优化版\n",
    "    current_solution = initialize_solution()\n",
    "    current_value = evaluate(current_solution)\n",
    "    best_solution = current_solution.copy()\n",
    "    best_value = current_value\n",
    "    \n",
    "    temperature = initial_temp\n",
    "    stagnation_count = 0\n",
    "    max_iterations = 1000  # 添加总迭代次数限制\n",
    "    \n",
    "    iteration = 0\n",
    "    while temperature > 1 and stagnation_count < max_stagnation and iteration < max_iterations:\n",
    "        improved = False\n",
    "        \n",
    "        for _ in range(iterations_per_temp):\n",
    "            # 生成新解\n",
    "            new_solution = generate_neighbor_fast(current_solution)\n",
    "            new_solution = repair_solution_fast(new_solution)\n",
    "            new_value = evaluate(new_solution)\n",
    "            \n",
    "            delta = current_value - new_value\n",
    "            \n",
    "            # Metropolis准则\n",
    "            if delta < 0 or random.random() < math.exp(-delta / temperature):\n",
    "                current_solution = new_solution\n",
    "                current_value = new_value\n",
    "                \n",
    "                if new_value > best_value:\n",
    "                    best_solution = new_solution.copy()\n",
    "                    best_value = new_value\n",
    "                    improved = True\n",
    "                    stagnation_count = 0\n",
    "            \n",
    "            iteration += 1\n",
    "        \n",
    "        if not improved:\n",
    "            stagnation_count += 1\n",
    "            \n",
    "        temperature *= cooling_rate\n",
    "        \n",
    "        # 提前退出条件\n",
    "        if iteration >= max_iterations:\n",
    "            break\n",
    "    \n",
    "    # 快速局部优化\n",
    "    def quick_local_optimize(solution):\n",
    "        \"\"\"对解进行快速局部优化\"\"\"\n",
    "        improved = True\n",
    "        while improved:\n",
    "            improved = False\n",
    "            # 尝试添加一个未选中的高价值密度物品\n",
    "            unselected = [i for i in range(n) if solution[i] == 0]\n",
    "            selected = [i for i in range(n) if solution[i] == 1]\n",
    "            current_weight = sum(items[i].w for i in selected)\n",
    "            \n",
    "            # 按价值密度排序\n",
    "            unselected_sorted = sorted(unselected, key=lambda i: items[i].v / items[i].w, reverse=True)\n",
    "            \n",
    "            for idx in unselected_sorted[:10]:  # 只检查前10个\n",
    "                if current_weight + items[idx].w <= C:\n",
    "                    # 检查是否可以添加\n",
    "                    solution[idx] = 1\n",
    "                    current_weight += items[idx].w\n",
    "                    improved = True\n",
    "                    break\n",
    "        \n",
    "        return solution\n",
    "    \n",
    "    # 对最终解进行快速局部优化\n",
    "    best_solution = quick_local_optimize(best_solution)\n",
    "    best_value = evaluate(best_solution)\n",
    "    \n",
    "    chosen_indices = [items[i].idx for i in range(n) if best_solution[i] == 1]\n",
    "    return best_value, chosen_indices\n",
    "\n",
    "def memetic_simulated_annealing_fast(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    快速记忆模拟退火算法 - 大幅优化运行时间\n",
    "    \n",
    "    主要优化：\n",
    "    1. 减小种群规模\n",
    "    2. 减少局部搜索迭代次数\n",
    "    3. 简化交叉和变异操作\n",
    "    \"\"\"\n",
    "    n = len(items)\n",
    "    \n",
    "    # 优化后的参数设置\n",
    "    if n <= 50:\n",
    "        initial_temp = 300\n",
    "        cooling_rate = 0.97\n",
    "        iterations_per_temp = 30\n",
    "        max_stagnation = 10\n",
    "        population_size = 5      # 减小种群规模\n",
    "        local_search_iterations = 5  # 减少局部搜索迭代次数\n",
    "    elif n <= 100:\n",
    "        initial_temp = 200\n",
    "        cooling_rate = 0.96\n",
    "        iterations_per_temp = 20\n",
    "        max_stagnation = 8\n",
    "        population_size = 4\n",
    "        local_search_iterations = 4\n",
    "    else:\n",
    "        initial_temp = 150\n",
    "        cooling_rate = 0.95\n",
    "        iterations_per_temp = 15\n",
    "        max_stagnation = 5\n",
    "        population_size = 3\n",
    "        local_search_iterations = 3\n",
    "    \n",
    "    # 快速初始化种群\n",
    "    def initialize_population_fast():\n",
    "        population = []\n",
    "        \n",
    "        # 策略1: 贪心密度策略（快速版）\n",
    "        density_sorted = sorted(range(n), key=lambda i: items[i].v / items[i].w, reverse=True)\n",
    "        solution = [0] * n\n",
    "        current_weight = 0\n",
    "        max_items = min(15, n)  # 限制初始化物品数量\n",
    "        for idx in density_sorted[:max_items]:\n",
    "            if current_weight + items[idx].w <= C:\n",
    "                solution[idx] = 1\n",
    "                current_weight += items[idx].w\n",
    "        population.append(solution)\n",
    "        \n",
    "        # 策略2: 随机策略（少量）\n",
    "        for _ in range(population_size - 1):\n",
    "            solution = [random.randint(0, 1) for _ in range(n)]\n",
    "            solution = repair_solution_fast(solution)\n",
    "            population.append(solution)\n",
    "        \n",
    "        return population\n",
    "    \n",
    "    def evaluate(solution):\n",
    "        total_value = 0\n",
    "        total_weight = 0\n",
    "        for i in range(n):\n",
    "            if solution[i] == 1:\n",
    "                total_value += items[i].v\n",
    "                total_weight += items[i].w\n",
    "        if total_weight > C:\n",
    "            return max(0, total_value - 1000 * (total_weight - C))\n",
    "        return total_value\n",
    "    \n",
    "    def repair_solution_fast(solution):\n",
    "        solution = solution.copy()\n",
    "        current_weight = sum(items[i].w for i in range(n) if solution[i] == 1)\n",
    "        \n",
    "        if current_weight > C:\n",
    "            selected_indices = [i for i in range(n) if solution[i] == 1]\n",
    "            if selected_indices:\n",
    "                sorted_by_density = sorted(\n",
    "                    selected_indices,\n",
    "                    key=lambda i: items[i].v / items[i].w\n",
    "                )\n",
    "                for idx in sorted_by_density:\n",
    "                    if current_weight <= C:\n",
    "                        break\n",
    "                    solution[idx] = 0\n",
    "                    current_weight -= items[idx].w\n",
    "        return solution\n",
    "    \n",
    "    # 快速局部搜索\n",
    "    def local_search_fast(solution, max_iterations):\n",
    "        best_solution = solution.copy()\n",
    "        best_value = evaluate(best_solution)\n",
    "        \n",
    "        # 减少局部搜索尝试次数\n",
    "        for _ in range(min(max_iterations, 5)):  # 最多5次尝试\n",
    "            neighbor = best_solution.copy()\n",
    "            idx = random.randint(0, n-1)\n",
    "            neighbor[idx] = 1 - neighbor[idx]\n",
    "            neighbor = repair_solution_fast(neighbor)\n",
    "            neighbor_value = evaluate(neighbor)\n",
    "            \n",
    "            if neighbor_value > best_value:\n",
    "                best_solution = neighbor\n",
    "                best_value = neighbor_value\n",
    "        \n",
    "        return best_solution\n",
    "    \n",
    "    # 简化交叉操作\n",
    "    def crossover_fast(parent1, parent2):\n",
    "        if n <= 1:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # 均匀交叉\n",
    "        child1 = [0] * n\n",
    "        child2 = [0] * n\n",
    "        \n",
    "        for i in range(n):\n",
    "            if random.random() < 0.5:\n",
    "                child1[i] = parent1[i]\n",
    "                child2[i] = parent2[i]\n",
    "            else:\n",
    "                child1[i] = parent2[i]\n",
    "                child2[i] = parent1[i]\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    # 简化变异操作\n",
    "    def mutate_fast(solution, mutation_rate=0.05):  # 降低变异率\n",
    "        mutated = solution.copy()\n",
    "        \n",
    "        # 只变异少量位置\n",
    "        mutation_count = max(1, int(n * mutation_rate))\n",
    "        for _ in range(mutation_count):\n",
    "            idx = random.randint(0, n-1)\n",
    "            mutated[idx] = 1 - mutated[idx]\n",
    "        \n",
    "        mutated = repair_solution_fast(mutated)\n",
    "        return mutated\n",
    "    \n",
    "    # 锦标赛选择（简化版）\n",
    "    def tournament_selection_fast(population, tournament_size=2):  # 减小锦标赛规模\n",
    "        tournament_indices = random.sample(range(len(population)), tournament_size)\n",
    "        tournament_solutions = [population[i] for i in tournament_indices]\n",
    "        tournament_values = [evaluate(s) for s in tournament_solutions]\n",
    "        \n",
    "        best_idx = tournament_indices[tournament_values.index(max(tournament_values))]\n",
    "        return population[best_idx]\n",
    "    \n",
    "    # 主算法流程（优化版）\n",
    "    population = initialize_population_fast()\n",
    "    population_values = [evaluate(s) for s in population]\n",
    "    best_solution = population[np.argmax(population_values)].copy()\n",
    "    best_value = max(population_values)\n",
    "    \n",
    "    temperature = initial_temp\n",
    "    stagnation_count = 0\n",
    "    max_generations = 50  # 限制最大代数\n",
    "    \n",
    "    generation = 0\n",
    "    while temperature > 1 and stagnation_count < max_stagnation and generation < max_generations:\n",
    "        new_population = []\n",
    "        \n",
    "        # 保留精英\n",
    "        elite_idx = np.argmax(population_values)\n",
    "        new_population.append(population[elite_idx].copy())\n",
    "        \n",
    "        improved = False\n",
    "        \n",
    "        # 生成新一代\n",
    "        while len(new_population) < population_size:\n",
    "            parent1 = tournament_selection_fast(population)\n",
    "            parent2 = tournament_selection_fast(population)\n",
    "            \n",
    "            child1, child2 = crossover_fast(parent1, parent2)\n",
    "            \n",
    "            child1 = mutate_fast(child1)\n",
    "            child2 = mutate_fast(child2)\n",
    "            \n",
    "            # 快速局部搜索\n",
    "            child1 = local_search_fast(child1, local_search_iterations)\n",
    "            child2 = local_search_fast(child2, local_search_iterations)\n",
    "            \n",
    "            # 评估并接受\n",
    "            for child in [child1, child2]:\n",
    "                child_value = evaluate(child)\n",
    "                parent_value = evaluate(parent1)\n",
    "                \n",
    "                delta = parent_value - child_value\n",
    "                \n",
    "                if delta < 0 or random.random() < math.exp(-delta / temperature):\n",
    "                    new_population.append(child)\n",
    "                    if child_value > best_value:\n",
    "                        best_solution = child.copy()\n",
    "                        best_value = child_value\n",
    "                        improved = True\n",
    "                        stagnation_count = 0\n",
    "        \n",
    "        population = new_population[:population_size]\n",
    "        population_values = [evaluate(s) for s in population]\n",
    "        \n",
    "        if not improved:\n",
    "            stagnation_count += 1\n",
    "            \n",
    "        temperature *= cooling_rate\n",
    "        generation += 1\n",
    "    \n",
    "    # 最终快速优化\n",
    "    def final_quick_optimize(solution):\n",
    "        \"\"\"最终快速优化\"\"\"\n",
    "        current_weight = sum(items[i].w for i in range(n) if solution[i] == 1)\n",
    "        \n",
    "        # 尝试添加未选中的高价值物品\n",
    "        unselected = [i for i in range(n) if solution[i] == 0]\n",
    "        # 按价值密度排序\n",
    "        unselected_sorted = sorted(unselected, key=lambda i: items[i].v / items[i].w, reverse=True)\n",
    "        \n",
    "        for idx in unselected_sorted[:15]:  # 只检查前15个\n",
    "            if current_weight + items[idx].w <= C:\n",
    "                solution[idx] = 1\n",
    "                current_weight += items[idx].w\n",
    "        \n",
    "        return solution\n",
    "    \n",
    "    best_solution = final_quick_optimize(best_solution)\n",
    "    best_value = evaluate(best_solution)\n",
    "    \n",
    "    chosen_indices = [items[i].idx for i in range(n) if best_solution[i] == 1]\n",
    "    return best_value, chosen_indices\n",
    "# ============================================================\n",
    "#  5.邓康\n",
    "# ============================================================\n",
    "@dataclass(order=True)\n",
    "class BBNode:\n",
    "    \"\"\"\n",
    "    分支限界树节点结构（用于增强版优先队列）\n",
    "    按上界值降序排列，Python的heapq是最小堆，因此用负值实现最大堆效果\n",
    "    \"\"\"\n",
    "    neg_bound: float = field(compare=True)  # 负的上界值（用于优先队列排序）\n",
    "    level: int = field(compare=False)       # 决策层级（已考虑的物品数）\n",
    "    value: int = field(compare=False)       # 当前总价值\n",
    "    weight: int = field(compare=False)      # 当前总重量\n",
    "    taken: List[int] = field(compare=False) # 已选物品索引\n",
    "    bound: float = field(compare=False)     # 上界值\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"确保taken列表是副本，避免引用问题\"\"\"\n",
    "        self.taken = self.taken.copy()\n",
    "\n",
    "# ---------- 辅助函数 ----------\n",
    "def fractional_knapsack_bound(\n",
    "    items: List[Item],\n",
    "    capacity: int,\n",
    "    level: int,\n",
    "    current_value: int,\n",
    "    current_weight: int\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    计算分数背包上界（贪心松弛上界）\n",
    "    \n",
    "    返回: (上界值, 分数部分的价值)\n",
    "    原理:\n",
    "    1. 从第level个物品开始（0-indexed，假设items已按密度降序排序）\n",
    "    2. 尽可能装入完整物品\n",
    "    3. 剩余容量装入第一个无法完整装入物品的一部分（按密度比例）\n",
    "    \"\"\"\n",
    "    if current_weight > capacity:\n",
    "        return -float('inf'), 0.0  # 不可行节点\n",
    "    \n",
    "    bound_value = float(current_value)\n",
    "    remaining_capacity = capacity - current_weight\n",
    "    \n",
    "    # 遍历剩余物品\n",
    "    for i in range(level, len(items)):\n",
    "        if items[i].w <= remaining_capacity:\n",
    "            # 可以完整装入\n",
    "            bound_value += items[i].v\n",
    "            remaining_capacity -= items[i].w\n",
    "        else:\n",
    "            # 只能装入一部分\n",
    "            fraction = remaining_capacity / items[i].w\n",
    "            fractional_value = items[i].v * fraction\n",
    "            bound_value += fractional_value\n",
    "            return bound_value, fractional_value\n",
    "    \n",
    "    return bound_value, 0.0  # 所有物品都能完整装入\n",
    "\n",
    "def sort_items_by_density(items: List[Item]) -> List[Item]:\n",
    "    \"\"\"按价值密度降序排序物品（用于上界计算）\"\"\"\n",
    "    return sorted(items, key=lambda x: x.v / x.w, reverse=True)\n",
    "\n",
    "# ---------- 动态规划验证 ----------\n",
    "def dp_optimal(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"容量维度 DP，O(nC)。规模过大时仅返回值，不回溯。\"\"\"\n",
    "    n = len(items)\n",
    "    dp = [0]*(C+1)\n",
    "    if (n+1)*(C+1) <= 2_000_000:\n",
    "        take = [[False]*(C+1) for _ in range(n)]\n",
    "        for i, it in enumerate(items):\n",
    "            w, v = it.w, it.v\n",
    "            for c in range(C, w-1, -1):\n",
    "                if dp[c-w] + v > dp[c]:\n",
    "                    dp[c] = dp[c-w] + v\n",
    "                    take[i][c] = True\n",
    "        c = max(range(C+1), key=lambda x: dp[x])\n",
    "        chosen = []\n",
    "        for i in range(n-1, -1, -1):\n",
    "            if take[i][c]:\n",
    "                chosen.append(items[i].idx)\n",
    "                c -= items[i].w\n",
    "        return max(dp), chosen[::-1]\n",
    "    else:\n",
    "        for it in items:\n",
    "            w, v = it.w, it.v\n",
    "            for c in range(C, w-1, -1):\n",
    "                if dp[c-w] + v > dp[c]:\n",
    "                    dp[c] = dp[c-w] + v\n",
    "        return max(dp), []\n",
    "\n",
    "# ---------- 算法一：基础分支限界法 (bb_basic) ----------\n",
    "def branch_and_bound_basic(\n",
    "    items: List[Item],\n",
    "    capacity: int\n",
    ") -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    基础分支限界法（深度优先搜索 + 分数背包上界剪枝）\n",
    "    返回: (最优价值, 最优解物品索引列表)\n",
    "    \n",
    "    算法特点:\n",
    "    1. 深度优先搜索（栈实现）\n",
    "    2. 物品按价值密度降序预处理，以获得更紧的上界\n",
    "    3. 使用分数背包上界进行剪枝\n",
    "    \n",
    "    性能指标:\n",
    "    - nodes_generated: 生成的节点总数\n",
    "    - nodes_explored: 实际探索的节点数\n",
    "    - first_opt_node: 首次找到最优解的节点编号\n",
    "    \"\"\"\n",
    "    # 按价值密度降序排序（提高上界质量）\n",
    "    sorted_items = sort_items_by_density(items)\n",
    "    n = len(sorted_items)\n",
    "    \n",
    "    # 性能指标记录\n",
    "    metrics = {\n",
    "        'nodes_generated': 1,  # 初始节点\n",
    "        'nodes_explored': 0,\n",
    "        'first_opt_node': 0\n",
    "    }\n",
    "    \n",
    "    # 全局最优解记录\n",
    "    best_value = 0\n",
    "    best_taken = []\n",
    "    \n",
    "    # 使用栈进行DFS（每个元素: (level, value, weight, taken)）\n",
    "    stack = [(0, 0, 0, [])]  # 从第0层开始\n",
    "    \n",
    "    while stack:\n",
    "        level, value, weight, taken = stack.pop()\n",
    "        metrics['nodes_explored'] += 1\n",
    "        \n",
    "        # 检查是否到达叶子节点\n",
    "        if level == n:\n",
    "            if value > best_value and weight <= capacity:\n",
    "                best_value = value\n",
    "                best_taken = taken\n",
    "                if metrics['first_opt_node'] == 0:\n",
    "                    metrics['first_opt_node'] = metrics['nodes_explored']\n",
    "            continue\n",
    "        \n",
    "        # 计算上界（包括当前节点的价值）\n",
    "        bound, _ = fractional_knapsack_bound(\n",
    "            sorted_items, capacity, level, value, weight\n",
    "        )\n",
    "        \n",
    "        # 剪枝：如果上界不大于当前最优解，放弃该分支\n",
    "        if bound <= best_value:\n",
    "            continue\n",
    "        \n",
    "        # 处理当前物品\n",
    "        current_item = sorted_items[level]\n",
    "        \n",
    "        # 分支1：不选当前物品（左子树）\n",
    "        stack.append((level + 1, value, weight, taken.copy()))\n",
    "        metrics['nodes_generated'] += 1\n",
    "        \n",
    "        # 分支2：选当前物品（右子树）- 需检查可行性\n",
    "        new_weight = weight + current_item.w\n",
    "        if new_weight <= capacity:\n",
    "            new_taken = taken + [current_item.idx]  # 记录原始索引\n",
    "            new_value = value + current_item.v\n",
    "            stack.append((level + 1, new_value, new_weight, new_taken))\n",
    "            metrics['nodes_generated'] += 1\n",
    "    \n",
    "    return best_value, best_taken\n",
    "\n",
    "# ---------- 算法二：增强分支限界法 (bb_enhanced) ----------\n",
    "def branch_and_bound_enhanced(\n",
    "    items: List[Item],\n",
    "    capacity: int\n",
    ") -> Tuple[int, List[int]]:\n",
    "    \"\"\"\n",
    "    增强分支限界法（探测技术 + 最佳上界优先）\n",
    "    \n",
    "    返回: (最优价值, 最优解物品索引列表)\n",
    "    \n",
    "    核心优化：\n",
    "    1. 探测技术（Probing）：分支前评估子问题潜力，提前剪枝无望分支\n",
    "    2. 最佳界限节点选择（Best-Bound Node Selection）：总是扩展上界最高的节点\n",
    "    \n",
    "    性能指标:\n",
    "    - nodes_generated: 生成的节点总数\n",
    "    - nodes_explored: 实际探索的节点数\n",
    "    - first_opt_node: 首次找到最优解的节点编号\n",
    "    - nodes_pruned_by_probing: 被探测技术剪枝的节点数\n",
    "    \"\"\"\n",
    "    # 按价值密度降序排序\n",
    "    sorted_items = sort_items_by_density(items)\n",
    "    n = len(sorted_items)\n",
    "    \n",
    "    # 性能指标记录\n",
    "    metrics = {\n",
    "        'nodes_generated': 1,  # 初始节点\n",
    "        'nodes_explored': 0,\n",
    "        'first_opt_node': 0,\n",
    "        'nodes_pruned_by_probing': 0\n",
    "    }\n",
    "    \n",
    "    # 全局最优解记录\n",
    "    best_value = 0\n",
    "    best_taken = []\n",
    "    \n",
    "    # 活节点表（优先队列）- 实现最佳界限优先\n",
    "    priority_queue = []\n",
    "    \n",
    "    # 创建初始节点（包含上界信息）\n",
    "    initial_bound, _ = fractional_knapsack_bound(\n",
    "        sorted_items, capacity, 0, 0, 0\n",
    "    )\n",
    "    heapq.heappush(\n",
    "        priority_queue,\n",
    "        BBNode(\n",
    "            neg_bound=-initial_bound,  # 负值实现最大堆（优先取上界高的）\n",
    "            level=0,\n",
    "            value=0,\n",
    "            weight=0,\n",
    "            taken=[],\n",
    "            bound=initial_bound\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    while priority_queue:\n",
    "        # 1：最佳界限节点选择\n",
    "        current_node = heapq.heappop(priority_queue)\n",
    "        metrics['nodes_explored'] += 1\n",
    "        \n",
    "        level = current_node.level\n",
    "        value = current_node.value\n",
    "        weight = current_node.weight\n",
    "        taken = current_node.taken\n",
    "        current_bound = current_node.bound\n",
    "        \n",
    "        # 检查是否到达叶子节点\n",
    "        if level == n:\n",
    "            if value > best_value and weight <= capacity:\n",
    "                best_value = value\n",
    "                best_taken = taken\n",
    "                if metrics['first_opt_node'] == 0:\n",
    "                    metrics['first_opt_node'] = metrics['nodes_explored']\n",
    "            continue\n",
    "        \n",
    "        current_item = sorted_items[level]\n",
    "        \n",
    "        # 2：探测技术（Probing）\n",
    "        # 评估左分支（不选当前物品）\n",
    "        left_bound, _ = fractional_knapsack_bound(\n",
    "            sorted_items, capacity, level + 1, value, weight\n",
    "        )\n",
    "        \n",
    "        # 评估右分支（选当前物品）- 仅在可行时\n",
    "        new_weight = weight + current_item.w\n",
    "        right_bound = -float('inf')\n",
    "        right_feasible = new_weight <= capacity\n",
    "        \n",
    "        if right_feasible:\n",
    "            new_value = value + current_item.v\n",
    "            right_bound, _ = fractional_knapsack_bound(\n",
    "                sorted_items, capacity, level + 1, new_value, new_weight\n",
    "            )\n",
    "        \n",
    "        # 基于探测结果的剪枝决策\n",
    "        max_child_bound = max(left_bound, right_bound) if right_feasible else left_bound\n",
    "        \n",
    "        if max_child_bound <= best_value:\n",
    "            # 所有子分支都不可能产生更优解，完全剪枝该节点\n",
    "            metrics['nodes_pruned_by_probing'] += 1\n",
    "            continue\n",
    "        \n",
    "        # 创建子节点，按上界值加入优先队列\n",
    "        # 先创建右分支（选当前物品）\n",
    "        if right_feasible and right_bound > best_value:\n",
    "            new_taken = taken + [current_item.idx]\n",
    "            new_value = value + current_item.v\n",
    "            \n",
    "            right_node = BBNode(\n",
    "                neg_bound=-right_bound,\n",
    "                level=level + 1,\n",
    "                value=new_value,\n",
    "                weight=new_weight,\n",
    "                taken=new_taken,\n",
    "                bound=right_bound\n",
    "            )\n",
    "            heapq.heappush(priority_queue, right_node)\n",
    "            metrics['nodes_generated'] += 1\n",
    "        \n",
    "        # 创建左分支（不选当前物品）\n",
    "        if left_bound > best_value:\n",
    "            left_node = BBNode(\n",
    "                neg_bound=-left_bound,\n",
    "                level=level + 1,\n",
    "                value=value,\n",
    "                weight=weight,\n",
    "                taken=taken.copy(),\n",
    "                bound=left_bound\n",
    "            )\n",
    "            heapq.heappush(priority_queue, left_node)\n",
    "            metrics['nodes_generated'] += 1\n",
    "    \n",
    "    return best_value, best_taken\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  6.杨昊哲\n",
    "# ============================================================\n",
    "def binary_cuckoo_search(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"二进制布谷鸟搜索算法求解0/1背包问题\"\"\"\n",
    "    if not items or C <= 0:\n",
    "        return 0, []\n",
    "    \n",
    "    n = len(items)\n",
    "    weights = np.array([item.w for item in items])\n",
    "    values = np.array([item.v for item in items])\n",
    "    indices = np.array([item.idx for item in items])\n",
    "    \n",
    "    # 参数设置\n",
    "    nest_count = max(15, min(30, n // 5 + 10))  # 巢穴数量\n",
    "    max_iter = max(40, min(120, n // 2 + 30))   # 最大迭代次数\n",
    "    pa = 0.25  # 丢弃概率\n",
    "    \n",
    "    # 初始化巢穴 (二进制表示)\n",
    "    nests = np.random.randint(0, 2, size=(nest_count, n))\n",
    "    \n",
    "    # 修复不可行解\n",
    "    def repair(particle):\n",
    "        total_weight = np.dot(particle, weights)\n",
    "        if total_weight <= C:\n",
    "            return particle.copy()\n",
    "        \n",
    "        # 按价值密度排序，移除低价值密度物品\n",
    "        density = values / (weights + 1e-10)\n",
    "        sorted_indices = np.argsort(-density)\n",
    "        \n",
    "        # 贪婪移除直到满足容量约束\n",
    "        for i in sorted_indices:\n",
    "            if particle[i] == 1:\n",
    "                particle[i] = 0\n",
    "                total_weight -= weights[i]\n",
    "                if total_weight <= C:\n",
    "                    break\n",
    "        return particle.copy()\n",
    "    \n",
    "    # 适应度评估\n",
    "    def fitness(particle):\n",
    "        total_weight = np.dot(particle, weights)\n",
    "        if total_weight > C:\n",
    "            return -1  # 不可行解\n",
    "        return np.dot(particle, values)\n",
    "    \n",
    "    # 初始化所有巢穴\n",
    "    for i in range(nest_count):\n",
    "        nests[i] = repair(nests[i])\n",
    "    \n",
    "    # 评估初始适应度\n",
    "    fitness_values = np.array([fitness(nest) for nest in nests])\n",
    "    \n",
    "    # 找到最佳解\n",
    "    best_idx = np.argmax(fitness_values)\n",
    "    best_nest = nests[best_idx].copy()\n",
    "    best_fitness = fitness_values[best_idx]\n",
    "    \n",
    "    # Levy flight 参数\n",
    "    beta = 1.5\n",
    "    sigma = (math.gamma(1 + beta) * math.sin(math.pi * beta / 2) / \n",
    "            (math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n",
    "    \n",
    "    # 主循环\n",
    "    for iter in range(max_iter):\n",
    "        # 生成新的解通过 Levy flight\n",
    "        new_nests = nests.copy()\n",
    "        \n",
    "        for i in range(nest_count):\n",
    "            # 生成 Levy flight 步长\n",
    "            u = np.random.normal(0, sigma, n)\n",
    "            v = np.random.normal(0, 1, n)\n",
    "            step = u / np.abs(v) ** (1 / beta)\n",
    "            \n",
    "            # 随机选择一个维度进行更新\n",
    "            step_size = 0.01 * step * (nests[i] - best_nest)\n",
    "            \n",
    "            # 更新位置\n",
    "            new_position = nests[i] + step_size\n",
    "            \n",
    "            # 转换为二进制 (使用 sigmoid 函数)\n",
    "            sigmoid = 1 / (1 + np.exp(-10 * new_position))\n",
    "            new_nest = (sigmoid > np.random.rand(n)).astype(int)\n",
    "            \n",
    "            # 修复并评估新解\n",
    "            new_nest = repair(new_nest)\n",
    "            new_fitness = fitness(new_nest)\n",
    "            \n",
    "            # 如果新解更好，则替换\n",
    "            if new_fitness > fitness_values[i]:\n",
    "                new_nests[i] = new_nest\n",
    "                fitness_values[i] = new_fitness\n",
    "        \n",
    "        # 选择更好的解\n",
    "        for i in range(nest_count):\n",
    "            if fitness_values[i] > best_fitness:\n",
    "                best_fitness = fitness_values[i]\n",
    "                best_nest = new_nests[i].copy()\n",
    "        \n",
    "        nests = new_nests\n",
    "        \n",
    "        # 随机丢弃部分解并生成新解\n",
    "        for i in range(nest_count):\n",
    "            if np.random.rand() < pa:\n",
    "                # 生成新解\n",
    "                new_nest = np.random.randint(0, 2, n)\n",
    "                new_nest = repair(new_nest)\n",
    "                new_fitness = fitness(new_nest)\n",
    "                \n",
    "                # 如果新解比当前解好，则替换\n",
    "                if new_fitness > fitness_values[i]:\n",
    "                    nests[i] = new_nest\n",
    "                    fitness_values[i] = new_fitness\n",
    "        \n",
    "        # 局部搜索 (每10代)\n",
    "        if iter % 10 == 0 and iter > 0:\n",
    "            # 对最佳解进行局部搜索\n",
    "            current_weight = np.dot(best_nest, weights)\n",
    "            current_value = np.dot(best_nest, values)\n",
    "            \n",
    "            # 尝试单点扰动\n",
    "            improved = False\n",
    "            for i in range(n):\n",
    "                if best_nest[i] == 0 and current_weight + weights[i] <= C:\n",
    "                    # 尝试添加物品\n",
    "                    test_nest = best_nest.copy()\n",
    "                    test_nest[i] = 1\n",
    "                    test_value = current_value + values[i]\n",
    "                    \n",
    "                    if test_value > best_fitness:\n",
    "                        best_nest = test_nest\n",
    "                        best_fitness = test_value\n",
    "                        current_weight += weights[i]\n",
    "                        current_value = test_value\n",
    "                        improved = True\n",
    "                \n",
    "                elif best_nest[i] == 1:\n",
    "                    # 尝试移除物品并添加其他物品\n",
    "                    test_nest = best_nest.copy()\n",
    "                    test_nest[i] = 0\n",
    "                    test_weight = current_weight - weights[i]\n",
    "                    test_value = current_value - values[i]\n",
    "                    \n",
    "                    # 尝试添加多个物品\n",
    "                    for j in range(n):\n",
    "                        if j != i and test_nest[j] == 0 and test_weight + weights[j] <= C:\n",
    "                            test_nest[j] = 1\n",
    "                            test_weight += weights[j]\n",
    "                            test_value += values[j]\n",
    "                    \n",
    "                    if test_value > best_fitness:\n",
    "                        best_nest = test_nest\n",
    "                        best_fitness = test_value\n",
    "                        current_weight = test_weight\n",
    "                        current_value = test_value\n",
    "                        improved = True\n",
    "    \n",
    "    # 返回结果\n",
    "    chosen_indices = indices[best_nest.astype(bool)].tolist()\n",
    "    return int(best_fitness), chosen_indices\n",
    "\n",
    "def binary_pso_knapsack(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"改进的二进制粒子群优化算法，具有自适应惯性权重与迭代策略\"\"\"\n",
    "    import numpy as np\n",
    "    n = len(items)\n",
    "    if n == 0 or C <= 0:\n",
    "        return 0, []\n",
    "    \n",
    "    weights = np.array([item.w for item in items])\n",
    "    values = np.array([item.v for item in items])\n",
    "    indices = np.array([item.idx for item in items])\n",
    "    \n",
    "    # 自适应参数设置\n",
    "    pop_size = max(20, min(50, n // 3 + 10))  # 种群大小\n",
    "    max_iter = max(30, min(100, n // 2 + 20))  # 最大迭代次数\n",
    "    \n",
    "    # 初始化粒子群\n",
    "    particles = np.random.randint(0, 2, size=(pop_size, n))\n",
    "    velocities = np.random.uniform(-1, 1, size=(pop_size, n))\n",
    "    \n",
    "    # 修复不可行解\n",
    "    def repair(particle):\n",
    "        total_weight = np.dot(particle, weights)\n",
    "        if total_weight <= C:\n",
    "            return particle.copy()\n",
    "        \n",
    "        # 按价值密度排序，移除低价值密度物品\n",
    "        density = values / (weights + 1e-10)\n",
    "        sorted_indices = np.argsort(-density)  # 从大到小排序\n",
    "        \n",
    "        # 贪婪移除直到满足容量约束\n",
    "        for i in sorted_indices:\n",
    "            if particle[i] == 1:\n",
    "                particle[i] = 0\n",
    "                total_weight -= weights[i]\n",
    "                if total_weight <= C:\n",
    "                    break\n",
    "        return particle.copy()\n",
    "    \n",
    "    # 适应度评估\n",
    "    def fitness(particle):\n",
    "        total_weight = np.dot(particle, weights)\n",
    "        if total_weight > C:\n",
    "            return -1  # 不可行解\n",
    "        return np.dot(particle, values)\n",
    "    \n",
    "    # 初始化个体历史最佳\n",
    "    pbest_positions = particles.copy()\n",
    "    pbest_fitness = np.array([fitness(p) for p in particles])\n",
    "    \n",
    "    # 初始化全局最佳\n",
    "    gbest_idx = np.argmax(pbest_fitness)\n",
    "    gbest_position = pbest_positions[gbest_idx].copy()\n",
    "    gbest_fitness = pbest_fitness[gbest_idx]\n",
    "    gbest_history = [gbest_fitness]\n",
    "    \n",
    "    # 主循环\n",
    "    for iter in range(max_iter):\n",
    "        # 自适应惯性权重: 从0.9线性下降到0.4\n",
    "        w = 0.9 - (0.9 - 0.4) * iter / max_iter\n",
    "        \n",
    "        for i in range(pop_size):\n",
    "            # 生成随机系数\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            \n",
    "            # 更新速度\n",
    "            velocities[i] = (w * velocities[i] + \n",
    "                            1.5 * r1 * (pbest_positions[i] - particles[i]) + \n",
    "                            1.5 * r2 * (gbest_position - particles[i]))\n",
    "            \n",
    "            # 更新位置 (Sigmoid映射)\n",
    "            sigmoid = 1 / (1 + np.exp(-velocities[i]))\n",
    "            particles[i] = (sigmoid > np.random.rand(n)).astype(int)\n",
    "            \n",
    "            # 修复不可行解\n",
    "            particles[i] = repair(particles[i])\n",
    "            \n",
    "            # 评估适应度\n",
    "            current_fitness = fitness(particles[i])\n",
    "            \n",
    "            # 更新个体最佳\n",
    "            if current_fitness > pbest_fitness[i]:\n",
    "                pbest_fitness[i] = current_fitness\n",
    "                pbest_positions[i] = particles[i].copy()\n",
    "            \n",
    "            # 更新全局最佳\n",
    "            if current_fitness > gbest_fitness:\n",
    "                gbest_fitness = current_fitness\n",
    "                gbest_position = particles[i].copy()\n",
    "        \n",
    "        gbest_history.append(gbest_fitness)\n",
    "        \n",
    "        # 每10代进行精英保留和多样性增强\n",
    "        if iter > 0 and iter % 10 == 0:\n",
    "            # 1. 精英保留：用全局最佳替换最差粒子\n",
    "            worst_idx = np.argmin(pbest_fitness)\n",
    "            particles[worst_idx] = gbest_position.copy()\n",
    "            pbest_positions[worst_idx] = gbest_position.copy()\n",
    "            pbest_fitness[worst_idx] = gbest_fitness\n",
    "            \n",
    "            # 2. 变异操作增强多样性\n",
    "            mutation_rate = 0.1 * (1 - iter / max_iter)  # 自适应变异率\n",
    "            for i in range(pop_size):\n",
    "                if np.random.rand() < 0.3:  # 30%的粒子进行变异\n",
    "                    particle = particles[i].copy()\n",
    "                    mask = np.random.rand(n) < mutation_rate\n",
    "                    particle[mask] = 1 - particle[mask]  # 位翻转变异\n",
    "                    particle = repair(particle)\n",
    "                    fitness_val = fitness(particle)\n",
    "                    \n",
    "                    # 如果变异后更好，更新个体历史最佳\n",
    "                    if fitness_val > pbest_fitness[i]:\n",
    "                        pbest_fitness[i] = fitness_val\n",
    "                        pbest_positions[i] = particle.copy()\n",
    "                    \n",
    "                    # 更新全局最佳\n",
    "                    if fitness_val > gbest_fitness:\n",
    "                        gbest_fitness = fitness_val\n",
    "                        gbest_position = particle.copy()\n",
    "    \n",
    "    # 局部搜索进一步改进全局最佳解\n",
    "    def local_search(solution):\n",
    "        current_weight = np.dot(solution, weights)\n",
    "        current_value = np.dot(solution, values)\n",
    "        \n",
    "        # 尝试单点扰动\n",
    "        for i in range(n):\n",
    "            if solution[i] == 0 and current_weight + weights[i] <= C:\n",
    "                # 尝试添加物品i\n",
    "                new_solution = solution.copy()\n",
    "                new_solution[i] = 1\n",
    "                new_value = current_value + values[i]\n",
    "                if new_value > current_value:\n",
    "                    return new_solution\n",
    "            \n",
    "            if solution[i] == 1:\n",
    "                # 尝试移除物品i，并尝试添加其他物品\n",
    "                new_solution = solution.copy()\n",
    "                new_solution[i] = 0\n",
    "                new_weight = current_weight - weights[i]\n",
    "                new_value = current_value - values[i]\n",
    "                \n",
    "                # 尝试添加多个物品\n",
    "                added = False\n",
    "                for j in range(n):\n",
    "                    if j != i and new_solution[j] == 0 and new_weight + weights[j] <= C:\n",
    "                        new_solution[j] = 1\n",
    "                        new_weight += weights[j]\n",
    "                        new_value += values[j]\n",
    "                        added = True\n",
    "                \n",
    "                if added and new_value > current_value:\n",
    "                    return new_solution\n",
    "        \n",
    "        return solution\n",
    "    \n",
    "    # 应用局部搜索\n",
    "    improved_solution = local_search(gbest_position)\n",
    "    improved_fitness = fitness(improved_solution)\n",
    "    if improved_fitness > gbest_fitness:\n",
    "        gbest_position = improved_solution\n",
    "        gbest_fitness = improved_fitness\n",
    "    \n",
    "    # 返回结果\n",
    "    chosen_indices = indices[gbest_position.astype(bool)].tolist()\n",
    "    return int(gbest_fitness), chosen_indices\n",
    "# ============================================================\n",
    "#  五、算法注册表\n",
    "# ============================================================\n",
    "\n",
    "ALGOS: Dict[str, AlgoFn] = {\n",
    "    \"GreedyDensity\":       greedy_density,\n",
    "    \"Greedy+Max\":          greedy_plus_max,\n",
    "    \"Classic_BeamSearch\":  algo_beam_search,\n",
    "    \"Bounded_BeamSearch\":  algo_beam_search_optimized,\n",
    "    \"run_GA\":              run_GA,   # 标准 GA\n",
    "    \"run_iGA\":             run_iGA,  # 岛屿 GA\n",
    "    \"SA_Fast\": simulated_annealing_knapsack_fast,\n",
    "    \"MemeticSA_Fast\": memetic_simulated_annealing_fast,\n",
    "    \"bb_basic\": branch_and_bound_basic,\n",
    "    \"bb_enhanced\": branch_and_bound_enhanced,\n",
    "    \"BinaryCuckooSearch\": binary_cuckoo_search,\n",
    "    \"BPSO\": binary_pso_knapsack\n",
    "}\n",
    "print('算法初步运行完成')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5fab1e",
   "metadata": {},
   "source": [
    "# 各算法性能指标及其可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "性能评估及其可视化完成并保存至outputs_analysis_section5文件夹\n"
     ]
    }
   ],
   "source": [
    "def dp_optimal(items: List[Item], C: int) -> Tuple[int, List[int]]:\n",
    "    \"\"\"容量维度 DP，O(nC)。规模过大时只返回值，不回溯。\"\"\"\n",
    "    n = len(items)\n",
    "    dp = [0] * (C + 1)\n",
    "    if (n + 1) * (C + 1) <= 2_000_000:\n",
    "        take = [[False] * (C + 1) for _ in range(n)]\n",
    "        for i, it in enumerate(items):\n",
    "            w, v = it.w, it.v\n",
    "            for c in range(C, w - 1, -1):\n",
    "                if dp[c - w] + v > dp[c]:\n",
    "                    dp[c] = dp[c - w] + v\n",
    "                    take[i][c] = True\n",
    "        c = max(range(C + 1), key=lambda x: dp[x])\n",
    "        chosen: List[int] = []\n",
    "        for i in range(n - 1, -1, -1):\n",
    "            if take[i][c]:\n",
    "                chosen.append(items[i].idx)\n",
    "                c -= items[i].w\n",
    "        return max(dp), chosen[::-1]\n",
    "    else:\n",
    "        for it in items:\n",
    "            w, v = it.w, it.v\n",
    "            for c in range(C, w - 1, -1):\n",
    "                if dp[c - w] + v > dp[c]:\n",
    "                    dp[c] = dp[c - w] + v\n",
    "        return max(dp), []\n",
    "\n",
    "def fractional_upper_bound(items: List[Item], C: int) -> float:\n",
    "    \"\"\"LP/分数背包上界\"\"\"\n",
    "    items_sorted = sorted(items, key=lambda x: (x.v / x.w, x.v), reverse=True)\n",
    "    tw = 0\n",
    "    tv = 0.0\n",
    "    for it in items_sorted:\n",
    "        if tw + it.w <= C:\n",
    "            tw += it.w\n",
    "            tv += it.v\n",
    "        else:\n",
    "            remain = C - tw\n",
    "            if remain > 0:\n",
    "                tv += (it.v / it.w) * remain\n",
    "            break\n",
    "    return tv\n",
    "\n",
    "# ============================================================\n",
    "#  七、实例生成器（⚙ 定义“数据集”的所有实例族）\n",
    "# ============================================================\n",
    "\n",
    "C_BASE_DEFAULT = 1000\n",
    "\n",
    "def _build_near_capacity_items(n, rng, C, w_lo=0.55, w_hi=0.75):\n",
    "    return [rng.randint(int(w_lo * C), int(w_hi * C)) for _ in range(n)]\n",
    "\n",
    "def _finish_with_big_item(items_small, C, rng, density_eps=0.01, big_w_ratio=0.95):\n",
    "    best_small = max(items_small, key=lambda it: it.v / it.w)\n",
    "    d_best = best_small.v / best_small.w\n",
    "    w_big = int(max(1, round(big_w_ratio * C)))\n",
    "    d_big = max(1e-9, d_best * (1.0 - density_eps))\n",
    "    v_big = int(math.ceil(d_big * w_big))\n",
    "    items = items_small + [Item(w=w_big, v=max(1, v_big), idx=len(items_small))]\n",
    "    return items\n",
    "\n",
    "def gen_uncorrelated(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT, v_lo=1, v_hi=1000):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = _build_near_capacity_items(n - 1, rng, C)\n",
    "    vs = [rng.randint(v_lo, v_hi) for _ in range(n - 1)]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "def gen_weakly_correlated(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT, noise=20):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = _build_near_capacity_items(n - 1, rng, C)\n",
    "    vs = [max(1, w + rng.randint(-noise, noise)) for w in ws]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "def gen_strongly_correlated(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT, delta=40):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = _build_near_capacity_items(n - 1, rng, C)\n",
    "    vs = [w + delta for w in ws]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "def gen_inversely_correlated(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = _build_near_capacity_items(n - 1, rng, C)\n",
    "    Wmax = max(ws)\n",
    "    vs = [max(1, Wmax - w + rng.randint(0, 20)) for w in ws]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "def gen_heavy_tailed(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT, pareto_alpha=2.0):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = []\n",
    "    for _ in range(n - 1):\n",
    "        raw = int(C * min(0.95, max(0.55, rng.paretovariate(pareto_alpha) / 10.0)))\n",
    "        w = int(min(max(0.55 * C, raw), 0.75 * C))\n",
    "        ws.append(w)\n",
    "    vs = [rng.randint(200, 1200) for _ in range(n - 1)]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "def gen_greedy_trap(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = _build_near_capacity_items(n - 1, rng, C)\n",
    "    vs = [int(math.ceil(1.02 * w + rng.uniform(-0.01, 0.01) * C)) for w in ws]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "def gen_greedy_trap_adv(n, seed, cap_ratio=0.5, delta=0.003, C_base=1000, w_lo=0.90, w_hi=0.98, d_small=1.01):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    n_small = max(1, n - 1)\n",
    "    items = []\n",
    "    for i in range(n_small):\n",
    "        w = rng.randint(int(w_lo * C), int(w_hi * C))\n",
    "        v = int(math.ceil(d_small * w))\n",
    "        items.append(Item(w=max(1, w), v=max(1, v), idx=i))\n",
    "    d_big = 0.95 * d_small + delta\n",
    "    v_big = int(math.ceil(d_big * C))\n",
    "    items.append(Item(w=C, v=max(1, v_big), idx=n_small))\n",
    "    return items, C\n",
    "\n",
    "def gen_uncorrelated_large(n, seed, cap_ratio=0.5, C_base=C_BASE_DEFAULT):\n",
    "    rng = random.Random(seed)\n",
    "    C = int(C_base)\n",
    "    ws = _build_near_capacity_items(n - 1, rng, C)\n",
    "    vs = [rng.randint(1, 1000) for _ in range(n - 1)]\n",
    "    items_small = [Item(ws[i], vs[i], i) for i in range(n - 1)]\n",
    "    return _finish_with_big_item(items_small, C, rng), C\n",
    "\n",
    "GENS = {\n",
    "    \"Uncorrelated\":       gen_uncorrelated,\n",
    "    \"WeaklyCorr\":         gen_weakly_correlated,\n",
    "    \"StronglyCorr\":       gen_strongly_correlated,\n",
    "    \"InverseCorr\":        gen_inversely_correlated,\n",
    "    \"HeavyTailed\":        gen_heavy_tailed,\n",
    "    \"GreedyTrap\":         gen_greedy_trap,\n",
    "    \"GreedyTrap-ADV\":     gen_greedy_trap_adv,\n",
    "    \"Uncorrelated-Large\": gen_uncorrelated_large,\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "#  八、单实例评测 & 主实验循环\n",
    "# ============================================================\n",
    "\n",
    "def run_instance(items: List[Item], C: int, allow_dp: bool = True):\n",
    "    n = len(items)\n",
    "    total_w = sum(it.w for it in items)\n",
    "\n",
    "    if allow_dp and n <= 200 and C <= 6000:\n",
    "        t0 = time.perf_counter()\n",
    "        opt_val, _ = dp_optimal(items, C)\n",
    "        opt_time = time.perf_counter() - t0\n",
    "        opt_known = True\n",
    "        UB = float(opt_val)\n",
    "    else:\n",
    "        opt_val = None\n",
    "        opt_time = None\n",
    "        opt_known = False\n",
    "        UB = fractional_upper_bound(items, C)\n",
    "\n",
    "    rows = []\n",
    "    for name, algo in ALGOS.items():\n",
    "        tracemalloc.start()\n",
    "        t0 = time.perf_counter()\n",
    "        val, _ = algo(items, C)\n",
    "        runtime = time.perf_counter() - t0\n",
    "        _, peak_memory = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "\n",
    "        if opt_known and UB > 0:\n",
    "            gap = (opt_val - val) / opt_val if opt_val > 0 else 0.0\n",
    "        else:\n",
    "            gap = (UB - val) / UB if UB > 0 else 0.0\n",
    "\n",
    "        rows.append({\n",
    "            \"algo\":       name,\n",
    "            \"value\":      int(val),\n",
    "            \"runtime_s\":  float(runtime),\n",
    "            \"peak_mem_kb\": float(peak_memory / 1024),\n",
    "            \"gap\":        float(gap),\n",
    "            \"opt_known\":  bool(opt_known),\n",
    "            \"capacity\":   int(C),\n",
    "            \"n\":          int(n),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def run_benchmark(seed_base: int = 2025) -> pd.DataFrame:\n",
    "    classes = [\n",
    "        (\"Uncorrelated\",       dict(n=60)),\n",
    "        (\"Uncorrelated-100\",   dict(n=100, gen=\"Uncorrelated\")),\n",
    "        (\"Uncorrelated-200\",   dict(n=200, gen=\"Uncorrelated\")),\n",
    "        # (\"Uncorrelated-Large\", dict(n=500)), # Uncomment for large scale test\n",
    "        (\"WeaklyCorr\",         dict(n=150)),\n",
    "        (\"StronglyCorr\",       dict(n=150)),\n",
    "        (\"InverseCorr\",        dict(n=150)),\n",
    "        (\"HeavyTailed\",        dict(n=150)),\n",
    "        (\"GreedyTrap\",         dict(n=150)),\n",
    "        (\"GreedyTrap-ADV\",     dict(n=13)),\n",
    "    ]\n",
    "\n",
    "    REPEATS = 5\n",
    "    SAMPLES_PER_REPEAT = 5\n",
    "\n",
    "    rows = []\n",
    "    print(f\"--- Starting Benchmark (Algos: {list(ALGOS.keys())}) ---\")\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    total_tasks = sum(REPEATS * SAMPLES_PER_REPEAT for _ in classes)\n",
    "    pbar = tqdm(total=total_tasks, desc=\"Running Experiments\")\n",
    "\n",
    "    for cls_name, params in classes:\n",
    "        gen = GENS[params.get(\"gen\", cls_name)]\n",
    "        for rep in range(REPEATS):\n",
    "            for s in range(SAMPLES_PER_REPEAT):\n",
    "                seed = seed_base + (stable_hash_str(cls_name, rep, s) % 10_000_000)\n",
    "                items, C = gen(params[\"n\"], seed)\n",
    "                allow_dp = (cls_name != \"Uncorrelated-Large\")\n",
    "                res = run_instance(items, C, allow_dp=allow_dp)\n",
    "                for r in res:\n",
    "                    r2 = {\"class\": cls_name, \"rep\": rep, \"sample\": s}\n",
    "                    r2.update(r)\n",
    "                    rows.append(r2)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_csv = os.path.join(OUTDIR, \"raw_results_section3.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] Results saved to: {out_csv}\")\n",
    "    return df\n",
    "# ============================================================\n",
    "#  IX. Advanced Visualization Analysis (8-Panel Version)\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "def analyze_and_plot(csv_path=\"outputs_exp_section3/raw_results_section3.csv\", \n",
    "                     output_dir=\"outputs_analysis_section5\"):\n",
    "    \"\"\"\n",
    "    Comprehensive Analysis Function (8-Panel Version):\n",
    "    Includes: Gap, Runtime, Memory, Scalability, Stability, Significance, Energy, WinRate\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"[Error] Data file {csv_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- [Analysis] Generating 8-panel analysis report... ---\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    has_mem = \"peak_mem_kb\" in df.columns\n",
    "\n",
    "    # Set plotting style\n",
    "    sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "    fig = plt.figure(figsize=(28, 12), constrained_layout=True)\n",
    "    gs = fig.add_gridspec(2, 4) \n",
    "\n",
    "    # --- Plot 1: Solution Quality (Gap) ---\n",
    "    ax_gap = fig.add_subplot(gs[0, 0])\n",
    "    sns.barplot(data=df, x=\"class\", y=\"gap\", hue=\"algo\", errorbar=(\"ci\", 95), \n",
    "                capsize=0.1, ax=ax_gap, palette=\"viridis\", alpha=0.9)\n",
    "    ax_gap.set_title(\"1. Solution Quality (Gap)\", fontweight=\"bold\")\n",
    "    ax_gap.set_ylabel(\"Gap to UB/OPT\")\n",
    "    ax_gap.tick_params(axis='x', rotation=25)\n",
    "    ax_gap.legend(loc='upper right', fontsize='small')\n",
    "\n",
    "    # --- Plot 2: Runtime ---\n",
    "    ax_time = fig.add_subplot(gs[0, 1])\n",
    "    sns.barplot(data=df, x=\"class\", y=\"runtime_s\", hue=\"algo\", errorbar=(\"ci\", 95),\n",
    "                capsize=0.1, ax=ax_time, palette=\"magma\", alpha=0.9)\n",
    "    ax_time.set_title(\"2. Runtime (Time Efficiency)\", fontweight=\"bold\")\n",
    "    ax_time.set_ylabel(\"Time (s)\")\n",
    "    ax_time.set_yscale(\"log\")\n",
    "    ax_time.tick_params(axis='x', rotation=25)\n",
    "    ax_time.legend(loc='upper left', fontsize='x-small', ncol=2, framealpha=0.8)\n",
    "\n",
    "    # --- Plot 3: Memory Usage ---\n",
    "    ax_mem = fig.add_subplot(gs[0, 2])\n",
    "    if has_mem:\n",
    "        sns.barplot(data=df, x=\"class\", y=\"peak_mem_kb\", hue=\"algo\", errorbar=(\"ci\", 95),\n",
    "                    capsize=0.1, ax=ax_mem, palette=\"rocket\", alpha=0.9)\n",
    "        ax_mem.set_title(\"3. Peak Memory Usage (KB)\", fontweight=\"bold\")\n",
    "        ax_mem.set_ylabel(\"Memory (KB)\")\n",
    "        ax_mem.tick_params(axis='x', rotation=25)\n",
    "        ax_mem.legend(loc='upper left', fontsize='x-small', ncol=2, framealpha=0.8)\n",
    "    else:\n",
    "        ax_mem.text(0.5, 0.5, \"No Memory Data\", ha='center')\n",
    "\n",
    "    # --- Plot 4: Scalability ---\n",
    "    ax_scale = fig.add_subplot(gs[0, 3])\n",
    "    # Filter for Uncorrelated class to fit\n",
    "    scale_df = df[df[\"class\"].str.contains(\"Uncorrelated\")].copy()\n",
    "    \n",
    "    # Only draw fit lines if different N values exist\n",
    "    if not scale_df.empty and scale_df[\"n\"].nunique() > 1:\n",
    "        algos = scale_df[\"algo\"].unique()\n",
    "        colors = sns.color_palette(\"bright\", n_colors=len(algos))\n",
    "        max_n = scale_df[\"n\"].max()\n",
    "        pred_n = int(max_n * 1.5) # Prediction range\n",
    "        \n",
    "        # 设置对数刻度（关键：防止高耗时算法压扁低耗时算法的曲线）\n",
    "        ax_scale.set_yscale('log')\n",
    "        \n",
    "        # 用于调整文本位置，避免重叠\n",
    "        text_offsets = np.linspace(0, len(algos)-1, len(algos))\n",
    "        \n",
    "        for idx, algo in enumerate(algos):\n",
    "            sub = scale_df[scale_df[\"algo\"] == algo].sort_values(\"n\")\n",
    "            if len(sub) < 2:\n",
    "                continue\n",
    "                \n",
    "            # 拟合模型：y = a * (n * log2(n)) + b\n",
    "            X = (sub[\"n\"] * np.log2(sub[\"n\"])).values.reshape(-1, 1)\n",
    "            y = sub[\"runtime_s\"].values\n",
    "            \n",
    "            try:\n",
    "                model = LinearRegression().fit(X, y)\n",
    "                \n",
    "                # 计算 R² 值\n",
    "                y_pred = model.predict(X)\n",
    "                r2 = r2_score(y, y_pred)\n",
    "                \n",
    "                # 生成拟合线\n",
    "                x_plot = np.linspace(sub[\"n\"].min(), pred_n, 100)\n",
    "                X_plot = (x_plot * np.log2(x_plot)).reshape(-1, 1)\n",
    "                y_plot = model.predict(X_plot)\n",
    "                \n",
    "                # 提取系数\n",
    "                a = model.coef_[0]\n",
    "                b = model.intercept_\n",
    "                \n",
    "                # 绘制拟合线（虚线，颜色与数据点一致）\n",
    "                ax_scale.plot(x_plot, y_plot, \"--\", color=colors[idx], linewidth=1.5, alpha=0.9, label=algo)\n",
    "                ax_scale.scatter(sub[\"n\"], sub[\"runtime_s\"], color=colors[idx], s=30, alpha=0.6)\n",
    "                \n",
    "                # 在拟合线终点标注公式\n",
    "                # 格式：f(n) = 1.2e-7 * nlogn + 0.005, R²=0.99\n",
    "                formula_text = f\"f(n)={a:.2e}·nlogn{b:+.2e}\\nR²={r2:.3f}\"\n",
    "                \n",
    "                # 根据索引调整垂直对齐，避免重叠\n",
    "                va = 'bottom' if idx % 2 == 0 else 'top'\n",
    "                \n",
    "                ax_scale.text(pred_n * 0.98, y_plot[-1], formula_text,\n",
    "                            fontsize=6, color=colors[idx], \n",
    "                            verticalalignment=va, horizontalalignment='right',\n",
    "                            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', \n",
    "                                    edgecolor=colors[idx], alpha=0.7, linewidth=0.5))\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Scalability fit failed for {algo}: {e}\")\n",
    "            \n",
    "        ax_scale.set_title(f\"4. Scalability (Trend)\", fontweight=\"bold\")\n",
    "        ax_scale.set_xlabel(\"N\")\n",
    "        ax_scale.set_ylabel(\"Runtime (s)\")\n",
    "        ax_scale.legend(loc=\"upper left\", fontsize=\"x-small\", framealpha=0.9)\n",
    "        ax_scale.grid(True, alpha=0.3, which='both', linestyle=':')\n",
    "    else:\n",
    "        ax_scale.text(0.5, 0.5, \"Need varying N for Scalability\", ha='center')\n",
    "        ax_scale.set_title(\"4. Scalability (Data Insufficient)\", fontweight=\"bold\")\n",
    "\n",
    "    # --- Plot 5: Stability (Variance) ---\n",
    "    ax_box = fig.add_subplot(gs[1, 0])\n",
    "    sns.boxplot(data=df, x=\"class\", y=\"gap\", hue=\"algo\", ax=ax_box, palette=\"viridis\", fliersize=1)\n",
    "    ax_box.set_title(\"5. Stability (Variance)\", fontweight=\"bold\")\n",
    "    ax_box.set_ylabel(\"Gap\")\n",
    "    ax_box.tick_params(axis='x', rotation=25)\n",
    "    ax_box.legend(loc='upper left', fontsize='x-small', ncol=2, framealpha=0.8)\n",
    "\n",
    "    # --- Plot 6: Significance Test ---\n",
    "    ax_sig = fig.add_subplot(gs[1, 1])\n",
    "    try:\n",
    "        best_algo = df.groupby(\"algo\")[\"gap\"].mean().idxmin()\n",
    "        classes = df[\"class\"].unique(); algos = df[\"algo\"].unique()\n",
    "        p_values = pd.DataFrame(index=classes, columns=[a for a in algos if a != best_algo])\n",
    "        \n",
    "        for cls in classes:\n",
    "            sub = df[df[\"class\"] == cls]\n",
    "            pivoted = sub.pivot_table(index=[\"rep\", \"sample\"], columns=\"algo\", values=\"gap\")\n",
    "            if best_algo in pivoted.columns:\n",
    "                for algo in algos:\n",
    "                    if algo == best_algo or algo not in pivoted.columns: continue\n",
    "                    # Only do t-test if sample size is sufficient\n",
    "                    if len(pivoted[best_algo]) > 1:\n",
    "                        try:\n",
    "                            stat, p = stats.ttest_rel(pivoted[best_algo], pivoted[algo])\n",
    "                            p_values.loc[cls, algo] = p\n",
    "                        except: p_values.loc[cls, algo] = 1.0\n",
    "                    else:\n",
    "                        p_values.loc[cls, algo] = 1.0 \n",
    "        \n",
    "        if not p_values.empty:\n",
    "            sns.heatmap(-np.log10(p_values.fillna(1.0).astype(float) + 1e-300), \n",
    "                        annot=True, fmt=\".1f\", cmap=\"Reds\", ax=ax_sig, cbar_kws={'label': '-log10(p)'})\n",
    "            ax_sig.set_title(f\"6. Significance vs {best_algo}\", fontweight=\"bold\")\n",
    "            ax_sig.set_ylabel(\"\")\n",
    "        else:\n",
    "             ax_sig.text(0.5, 0.5, \"Cannot compute p-values\", ha='center')\n",
    "    except Exception as e:\n",
    "        ax_sig.text(0.5, 0.5, \"Significance Error\", ha='center')\n",
    "\n",
    "    # --- Plot 7: Energy Consumption Proxy ---\n",
    "    ax_nrg = fig.add_subplot(gs[1, 2])\n",
    "    sns.barplot(data=df, x=\"class\", y=\"runtime_s\", hue=\"algo\", errorbar=(\"ci\", 95),\n",
    "                capsize=0.1, ax=ax_nrg, palette=\"inferno\", alpha=0.9)\n",
    "    ax_nrg.set_title(\"7. Energy Consumption (Proxy)\", fontweight=\"bold\")\n",
    "    ax_nrg.set_ylabel(\"Energy Proxy (∝ Time)\")\n",
    "    ax_nrg.set_yscale(\"log\")\n",
    "    ax_nrg.tick_params(axis='x', rotation=25)\n",
    "    ax_nrg.legend(loc='upper left', fontsize='x-small', ncol=2, framealpha=0.8)\n",
    "\n",
    "    # --- Plot 8: Overall Win Rate ---\n",
    "    ax_win = fig.add_subplot(gs[1, 3])\n",
    "    try:\n",
    "        df[\"sample_id\"] = df[\"class\"] + \"_\" + df[\"rep\"].astype(str) + \"_\" + df[\"sample\"].astype(str)\n",
    "        wide_df = df.pivot(index=\"sample_id\", columns=\"algo\", values=\"gap\")\n",
    "        win_counts = {a: 0 for a in df[\"algo\"].unique()}; total = len(wide_df)\n",
    "        if total > 0:\n",
    "            for _, row in wide_df.iterrows():\n",
    "                # Winner has the minimum gap\n",
    "                min_gap = row.min()\n",
    "                # Handle ties: split points if multiple algorithms tie for best\n",
    "                winners = row[row == min_gap].index.tolist()\n",
    "                for w in winners: win_counts[w] += 1 / len(winners)\n",
    "            \n",
    "            # Draw Pie Chart\n",
    "            pd.Series(win_counts).plot(kind=\"pie\", autopct=\"%1.1f%%\", ax=ax_win, cmap=\"Pastel1\", ylabel=\"\")\n",
    "            ax_win.set_title(\"8. Overall Win Rate\", fontweight=\"bold\")\n",
    "        else:\n",
    "             ax_win.text(0.5, 0.5, \"No Data for Win Rate\", ha='center')\n",
    "    except:\n",
    "        ax_win.text(0.5, 0.5, \"Win Rate Error\", ha='center')\n",
    "\n",
    "    # Save\n",
    "    plot_path = os.path.join(output_dir, \"comprehensive_analysis_8panel.png\")\n",
    "    plt.savefig(plot_path, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # --- Trigger Popup Window ---\n",
    "    print(f\"\\n[OK] 8-Panel Analysis Plot Saved: {plot_path}\")\n",
    "    print(\"Attempting to show plot window...\")\n",
    "    plt.show() \n",
    "    plt.close()\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 运行基准测试生成数据\n",
    "    df = run_benchmark()\n",
    "\n",
    "    # 2. 输出简要汇总到控制台\n",
    "    summary = (\n",
    "        df.groupby([\"class\", \"algo\"])\n",
    "          .agg(mean_gap=(\"gap\", \"mean\"),\n",
    "               var_gap=(\"gap\", \"var\"),\n",
    "               mean_time=(\"runtime_s\", \"mean\"),\n",
    "               var_time=(\"runtime_s\", \"var\"),\n",
    "               cnt=(\"gap\", \"size\"))\n",
    "          .reset_index()\n",
    "    )\n",
    "    out_sum = os.path.join(OUTDIR, \"summary_preview_section3.csv\")\n",
    "    summary.to_csv(out_sum, index=False)\n",
    "    #print(f\"[OK] Preview summary saved to: {out_sum}\")\n",
    "    #print(summary.head(12))\n",
    "\n",
    "    analyze_and_plot()\n",
    "    print('性能评估及其可视化完成并保存至outputs_analysis_section5文件夹')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
